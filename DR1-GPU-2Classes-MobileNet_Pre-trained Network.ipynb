{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Without Pre Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatma-sayed/anaconda3/envs/keras-test/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n",
      "/home/fatma-sayed/anaconda3/envs/keras-test/lib/python3.6/site-packages/sklearn/cross_validation.py:41: DeprecationWarning: This module was deprecated in version 0.18 in favor of the model_selection module into which all the refactored classes and functions are moved. Also note that the interface of the new CV iterators are different from that of this module. This module will be removed in 0.20.\n",
      "  \"This module will be removed in 0.20.\", DeprecationWarning)\n",
      "/home/fatma-sayed/anaconda3/envs/keras-test/lib/python3.6/site-packages/keras/applications/mobilenet.py:224: UserWarning: MobileNet shape is undefined. Weights for input shape (224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://github.com/fchollet/deep-learning-models/releases/download/v0.6/mobilenet_1_0_224_tf_no_top.h5\n",
      "17227776/17225924 [==============================] - 12s 1us/step\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, None, None, 32)    864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_pad_1 (ZeroPadding2D)   (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, None, None, 32)    288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, None, None, 64)    2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, None, None, 64)    576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, None, None, 128)   8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_3 (ZeroPadding2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, None, None, 128)   16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, None, None, 256)   32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_5 (ZeroPadding2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, None, None, 256)   65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, None, None, 512)   131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_7 (ZeroPadding2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (Activation)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (Activation)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_8 (ZeroPadding2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (Activation)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (Activation)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_9 (ZeroPadding2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (Activation)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (Activation)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_10 (ZeroPadding2D)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (Activation) (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (Activation) (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_11 (ZeroPadding2D)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (Activation) (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (Activation) (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (Activation) (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, None, None, 1024)  524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (Activation) (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_pad_13 (ZeroPadding2D)  (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, None, None, 1024)  9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (Activation) (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, None, None, 1024)  1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (Activation) (None, None, None, 1024)  0         \n",
      "=================================================================\n",
      "Total params: 3,228,864\n",
      "Trainable params: 3,206,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n",
      " train_labels shape (1000,)\n",
      " train_labels : \n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1]\n",
      " validation_labels shape (400,)\n",
      " validation_labels : \n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Train on 1000 samples, validate on 400 samples\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 8.0189 - acc: 0.5010 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 7.6852 - acc: 0.5140 - val_loss: 8.0065 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 6.7205 - acc: 0.5660 - val_loss: 7.8283 - val_acc: 0.5075\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 4.7562 - acc: 0.6940 - val_loss: 5.8389 - val_acc: 0.6150\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 4.2880 - acc: 0.7170 - val_loss: 5.5445 - val_acc: 0.6475\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 3.9181 - acc: 0.7430 - val_loss: 2.9797 - val_acc: 0.8025\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 3.6712 - acc: 0.7640 - val_loss: 3.7849 - val_acc: 0.7575\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 3.4426 - acc: 0.7760 - val_loss: 3.0467 - val_acc: 0.7875\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 3.8460 - acc: 0.7540 - val_loss: 3.2440 - val_acc: 0.7925\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 3.3119 - acc: 0.7810 - val_loss: 2.9557 - val_acc: 0.8100\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 3.2461 - acc: 0.7910 - val_loss: 3.4342 - val_acc: 0.7725\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 2.7797 - acc: 0.8180 - val_loss: 2.6911 - val_acc: 0.8225\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 3.2296 - acc: 0.7920 - val_loss: 2.9852 - val_acc: 0.8075\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 3.1864 - acc: 0.7940 - val_loss: 2.6334 - val_acc: 0.8350\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 3.1270 - acc: 0.7990 - val_loss: 2.7386 - val_acc: 0.8250\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 3.1840 - acc: 0.7970 - val_loss: 2.6916 - val_acc: 0.8250\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 2.7620 - acc: 0.8240 - val_loss: 2.8879 - val_acc: 0.8125\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 2.6938 - acc: 0.8270 - val_loss: 2.6486 - val_acc: 0.8250\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 2.7777 - acc: 0.8150 - val_loss: 2.9830 - val_acc: 0.8050\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 2.6488 - acc: 0.8290 - val_loss: 2.5588 - val_acc: 0.8325\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 2.8704 - acc: 0.8140 - val_loss: 2.8829 - val_acc: 0.8175\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 2.9177 - acc: 0.8110 - val_loss: 3.4210 - val_acc: 0.7800\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 2.7974 - acc: 0.8200 - val_loss: 2.7332 - val_acc: 0.8225\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 2.7206 - acc: 0.8260 - val_loss: 3.0110 - val_acc: 0.8075\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 2.7384 - acc: 0.8270 - val_loss: 2.6157 - val_acc: 0.8350\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 2.7387 - acc: 0.8260 - val_loss: 2.9022 - val_acc: 0.8175\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 2.8944 - acc: 0.8140 - val_loss: 2.8261 - val_acc: 0.8150\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 3.0895 - acc: 0.8020 - val_loss: 3.1489 - val_acc: 0.8000\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 2.7614 - acc: 0.8220 - val_loss: 2.5793 - val_acc: 0.8300\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 2.7408 - acc: 0.8180 - val_loss: 2.4903 - val_acc: 0.8350\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 2.7607 - acc: 0.8220 - val_loss: 2.6911 - val_acc: 0.8275\n",
      "-------------------------------------------------------------------\n",
      "------------------ Evalute the train set ------------------------\n",
      "-------------------------------------------------------------------\n",
      "Train loss: 2.1758739970735967\n",
      "Train accuracy: 0.863\n",
      " y_pred_train shape (1000,)\n",
      " y_pred_train : \n",
      "  [0.0000000e+00 0.0000000e+00 4.0983806e-21 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 2.1826877e-35 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 1.3844785e-18 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.7025455e-05 1.1476218e-05\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 8.2661111e-10\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 3.2590905e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 3.1487705e-35 3.6702804e-34\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.8640927e-18 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0297934e-37 0.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 3.4495958e-25 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 5.6998282e-31 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 2.9467981e-22 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 3.4861491e-04 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.0311151e-20 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 6.4452661e-38 0.0000000e+00 2.4702449e-01 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.2160129e-08 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 4.6678302e-13 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 9.9999988e-01 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 7.3335205e-09\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 2.5434903e-36\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 9.9999988e-01\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.2672819e-21\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 2.1884555e-10 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 2.2417202e-37 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 9.9999928e-01 1.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 9.9999976e-01\n",
      " 1.0000000e+00 1.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 9.7126116e-13 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 9.9997854e-01 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 0.0000000e+00 4.4580791e-04 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 2.5277938e-08 0.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 0.0000000e+00 1.0000000e+00 1.4344181e-12\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 4.0251268e-20 1.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 2.8435316e-13 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 3.0195678e-38 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 0.0000000e+00 2.8347328e-20 1.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 2.1223518e-16 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.5480310e-02 1.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00 6.0786154e-34\n",
      " 1.0000000e+00 1.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 9.2979527e-01\n",
      " 1.0000000e+00 1.8727873e-19 1.0000000e+00 6.8995935e-01 0.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.0000000e+00 8.2366682e-13 1.0000000e+00\n",
      " 1.4014266e-10 9.9625797e-22 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 5.3323519e-14 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 4.3055747e-06 0.0000000e+00 7.2535211e-38 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 0.0000000e+00 3.8155985e-27 1.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 7.5212137e-10 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 5.0443948e-13 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 7.4196180e-30 0.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      " y_pred_train again: \n",
      "  [0 0 0 0 0 0 0 0 0 1 1 1 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 1\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0\n",
      " 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0\n",
      " 0 0 0 0 0 0 0 1 0 0 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 1 1 0 0 0\n",
      " 0 0 1 1 1 0 0 0 0 0 0 0 0 1 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 0 0\n",
      " 0 0 1 0 0 0 0 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1\n",
      " 0 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 0 1 1 1 1 0 1 1 1 1 1 1 0 1 0 0 1 1 1 1 1 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 0 1 0 1 1 1 0 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 1 1 1 0 0 1 1 1 1 1 0 0 0 1 1 1 1 0 0 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 0 1 1 1\n",
      " 1 0 0 1 1 0 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1\n",
      " 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 0 1 0 0 1 1 1 1 1 1 1 0 1\n",
      " 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 1 0 0 1 1 0 1 1 1 1 0 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 1 1 0 1 1 1 1 0 1 1 1 1 1 0 1 1\n",
      " 1 1 1 0 0 1 0 0 1 1 1 1 1 1 1 1 0 0 0 1 1 1 1 1 1 1 1 0 0 1 1 1 1 1 1 0 1\n",
      " 1 1 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1\n",
      " 1]\n",
      "accuracy_score_train with normalize=True:  0.863\n",
      "accuracy_score_train with normalize=False :  863\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.89      0.84      0.87       531\n",
      "    class 1       0.83      0.89      0.86       469\n",
      "\n",
      "avg / total       0.86      0.86      0.86      1000\n",
      "\n",
      "confusion_matrix : \n",
      " [[447  84]\n",
      " [ 53 416]]\n",
      "Accuracy :  0.863\n",
      "Sensitivity :  0.894\n",
      "Specificity :  0.832\n",
      "-------------------------------------------------------------------\n",
      "------------------ Evalute the validation set ------------------------\n",
      "-------------------------------------------------------------------\n",
      "validation loss: 2.6910876965522785\n",
      "validation accuracy: 0.8275\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y_pred_validation shape (400,)\n",
      " y_pred_validation : \n",
      "  [0.0000000e+00 1.0160267e-30 1.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.2900493e-23 5.9943617e-26 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 6.9096137e-17 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 9.9999142e-01 0.0000000e+00 0.0000000e+00 8.1873943e-31 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 4.4805473e-36 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 9.1739976e-01 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+00 7.2869178e-29 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 8.5211830e-30\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 4.5642469e-11 1.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 2.0926021e-09 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 9.9982065e-01 0.0000000e+00 1.0000000e+00\n",
      " 9.7869575e-17 1.0000000e+00 5.0798750e-29 0.0000000e+00 1.5988109e-32\n",
      " 0.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00 9.2625422e-23\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.6130126e-30\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 3.0702564e-38 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 0.0000000e+00 3.3377806e-13 8.3553620e-27\n",
      " 1.0000000e+00 1.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.5385995e-25 0.0000000e+00 1.0000000e+00 5.6479115e-02\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 9.9999928e-01 1.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 1.0294981e-31 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 2.8230315e-30 0.0000000e+00 9.9999952e-01 1.0000000e+00 3.9295723e-37\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 0.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 0.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00\n",
      " 1.0000000e+00 2.1710724e-18 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.7430186e-11 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 0.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 0.0000000e+00 1.0000000e+00 1.0000000e+00 0.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00\n",
      " 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00 1.0000000e+00]\n",
      " y_pred_validation again: \n",
      "  [0 0 1 1 0 0 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 1\n",
      " 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 1 0 0 0 1 0 1 1 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 0 0 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 1 1 0 0 0 0 1 1 0 0 1 1 1 1 1 0 1 0 1 0 1 0 0 0 0 0 1 1 0 1 1\n",
      " 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 0 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 0 1 0 1 1 1 1 1 1 1 1 1 1 0 0 1 1 1 0 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1\n",
      " 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 0 0 0 0 1 1 1 1 1 1 1 0 0 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 0 1 0 1 1 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 0 1 1 0 1 1 1 1 0 1 1 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "accuracy_score_validation with normalize=True:  0.8275\n",
      "accuracy_score_validation with normalize=False :  331\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       0.86      0.80      0.83       215\n",
      "    class 1       0.79      0.85      0.82       185\n",
      "\n",
      "avg / total       0.83      0.83      0.83       400\n",
      "\n",
      "confusion_matrix : \n",
      " [[173  42]\n",
      " [ 27 158]]\n",
      "Accuracy :  0.8275\n",
      "Sensitivity :  0.865\n",
      "Specificity :  0.79\n",
      "-------------------------------------------------------------------\n",
      "------------------ Train Done -------------------------------------\n",
      "-------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import keras\n",
    "import os\n",
    "\n",
    "from subprocess import check_output\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from PIL import Image\n",
    "#from keras.applications.vgg16 import preprocess_input\n",
    "#from keras.applications.xception import preprocess_input\n",
    "#from keras.applications.inception_v3 import preprocess_input\n",
    "#from keras.applications.vgg19 import preprocess_input                \n",
    "#from keras.applications.resnet50 import preprocess_input            \n",
    "#from keras.applications.inception_resnet_v2 import preprocess_input               \n",
    "from keras.applications.mobilenet import preprocess_input               \n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "\n",
    "#from keras.applications.xception import Xception\n",
    "\n",
    "#from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "#from keras.applications.vgg19 import VGG19\n",
    "\n",
    "#from keras.applications.resnet50 import ResNet50   \n",
    "\n",
    "#from keras.applications.inception_resnet_v2 import InceptionResNetV2    \n",
    "\n",
    "from keras.applications.mobilenet import MobileNet    \n",
    "\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from keras.layers import Dense, Dropout, Reshape\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten \n",
    "from keras import backend as K\n",
    "from keras import applications\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' #use GPU with ID=0\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7 # maximun alloc gpu50% of MEM\n",
    "#config.gpu_options.allow_growth = True #allocate dynamically\n",
    "sess = tf.Session(config = config)\n",
    "keras.backend.set_session(sess)\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "top_model_weights_path = 'bottleneck_fc_model_MobileNet_data4.h5'  \n",
    "train_data_dir = '../data4_Train500_Test200/train'\n",
    "validation_data_dir = '../data4_Train500_Test200/validation'\n",
    "nb_train_samples = 1000\n",
    "nb_validation_samples = 400\n",
    "epochs = 50\n",
    "batch_size = 8  # batch size in flow_images_from_directory needs to correspond to the image number of the test images.\n",
    "\n",
    "\n",
    "def save_bottleneck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the Inception_ResNet_V2 network\n",
    "\n",
    "    model = applications.MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    \n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    np.save(open('DR1_bottleneck_features_train_MobileNet_data4.npy', 'wb'),\n",
    "            bottleneck_features_train)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    np.save(open('DR1_bottleneck_features_validation_MobileNet_data4.npy', 'wb'),\n",
    "            bottleneck_features_validation)\n",
    "\n",
    "\n",
    "def train_top_model():\n",
    "    train_data = np.load(open('DR1_bottleneck_features_train_MobileNet_data4.npy','rb'))\n",
    "    train_labels = np.array(\n",
    "        [0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "\n",
    "    print(' train_labels shape',train_labels.shape)\n",
    "\n",
    "    print(' train_labels : \\n ',train_labels)\n",
    "\n",
    "    validation_data = np.load(open('DR1_bottleneck_features_validation_MobileNet_data4.npy','rb'))\n",
    "    validation_labels = np.array(\n",
    "        [0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
    "\n",
    "    print(' validation_labels shape',validation_labels.shape)\n",
    "\n",
    "    print(' validation_labels : \\n ',validation_labels)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)\n",
    "    \n",
    "    print('-------------------------------------------------------------------')\n",
    "    print('------------------ Evalute the train set ------------------------')\n",
    "    print('-------------------------------------------------------------------')\n",
    "\n",
    "    train_score = model.evaluate(train_data, train_labels, verbose=0) # nb_train_samples // batch_size, workers=1)\n",
    "    print('Train loss:', train_score[0])\n",
    "    print('Train accuracy:', train_score[1])\n",
    "\n",
    "    y_pred_train = np.squeeze(model.predict(train_data))\n",
    "    print(' y_pred_train shape',y_pred_train.shape)\n",
    "    print(' y_pred_train : \\n ',y_pred_train)\n",
    "\n",
    "    threshold = 0.5\n",
    "    y_pred_train = (y_pred_train > threshold)*1\n",
    "    #y_pred_train.astype(int)   \n",
    "    print(' y_pred_train again: \\n ',y_pred_train)\n",
    "    \n",
    "    accuracy_score_train = accuracy_score(train_labels, y_pred_train, normalize=True)\n",
    "    print('accuracy_score_train with normalize=True: ', accuracy_score_train)\n",
    "\n",
    "    accuracy_score_train = accuracy_score(train_labels, y_pred_train, normalize=False)\n",
    "    print('accuracy_score_train with normalize=False : ', accuracy_score_train)\n",
    "\n",
    "    target_names = ['class 0', 'class 1']\n",
    "\n",
    "    print(classification_report(y_pred_train, train_labels, target_names=target_names))\n",
    "\n",
    "    cm1 = confusion_matrix(y_pred_train, train_labels)\n",
    "    \n",
    "    print('confusion_matrix : \\n', cm1)\n",
    "\n",
    "    total1=sum(sum(cm1))\n",
    "\n",
    "    #####from confusion matrix calculate accuracy\n",
    "    accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
    "    print ('Accuracy : ', accuracy1)\n",
    "\n",
    "    sensitivity = cm1[0,0]/(cm1[0,0]+cm1[1,0])\n",
    "    print('Sensitivity : ', sensitivity )\n",
    "\n",
    "    Specificity = cm1[1,1]/(cm1[1,1]+cm1[0,1])\n",
    "    print('Specificity : ', Specificity )\n",
    "\n",
    "    print('-------------------------------------------------------------------')\n",
    "    print('------------------ Evalute the validation set ------------------------')\n",
    "    print('-------------------------------------------------------------------')\n",
    "\n",
    "    validation_score = model.evaluate(validation_data, validation_labels, verbose=0) # nb_train_samples // batch_size, workers=1)\n",
    "    print('validation loss:', validation_score[0])\n",
    "    print('validation accuracy:', validation_score[1])\n",
    "\n",
    "    y_pred_validation = np.squeeze(model.predict(validation_data))\n",
    "    print(' y_pred_validation shape',y_pred_validation.shape)\n",
    "    print(' y_pred_validation : \\n ',y_pred_validation)\n",
    "\n",
    "    y_pred_validation = (y_pred_validation > threshold)*1\n",
    "    #y_pred_train.astype(int)   \n",
    "    print(' y_pred_validation again: \\n ',y_pred_validation)\n",
    "    \n",
    "    accuracy_score_validation = accuracy_score(validation_labels, y_pred_validation, normalize=True)\n",
    "    print('accuracy_score_validation with normalize=True: ', accuracy_score_validation)\n",
    "\n",
    "    accuracy_score_validation = accuracy_score(validation_labels, y_pred_validation, normalize=False)\n",
    "    print('accuracy_score_validation with normalize=False : ', accuracy_score_validation)\n",
    "\n",
    "    print(classification_report(y_pred_validation, validation_labels, target_names=target_names))\n",
    "\n",
    "    cm1 = confusion_matrix(y_pred_validation, validation_labels)\n",
    "    \n",
    "    print('confusion_matrix : \\n', cm1)\n",
    "\n",
    "    total1=sum(sum(cm1))\n",
    "\n",
    "    #####from confusion matrix calculate accuracy\n",
    "    accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
    "    print ('Accuracy : ', accuracy1)\n",
    "\n",
    "    sensitivity = cm1[0,0]/(cm1[0,0]+cm1[1,0])\n",
    "    print('Sensitivity : ', sensitivity )\n",
    "\n",
    "    Specificity = cm1[1,1]/(cm1[1,1]+cm1[0,1])\n",
    "    print('Specificity : ', Specificity )\n",
    "\n",
    "\n",
    "save_bottleneck_features()\n",
    "train_top_model()\n",
    "\n",
    "print('-------------------------------------------------------------------')\n",
    "print('------------------ Train Done -------------------------------------')\n",
    "print('-------------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "### With Pre Process"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatma-sayed/anaconda3/envs/keras-test/lib/python3.6/site-packages/keras/applications/mobilenet.py:224: UserWarning: MobileNet shape is undefined. Weights for input shape (224, 224) will be loaded.\n",
      "  warnings.warn('MobileNet shape is undefined.'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv1_pad (ZeroPadding2D)    (None, None, None, 3)     0         \n",
      "_________________________________________________________________\n",
      "conv1 (Conv2D)               (None, None, None, 32)    864       \n",
      "_________________________________________________________________\n",
      "conv1_bn (BatchNormalization (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv1_relu (Activation)      (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_pad_1 (ZeroPadding2D)   (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_1 (DepthwiseConv2D)  (None, None, None, 32)    288       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_bn (BatchNormaliza (None, None, None, 32)    128       \n",
      "_________________________________________________________________\n",
      "conv_dw_1_relu (Activation)  (None, None, None, 32)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_1 (Conv2D)           (None, None, None, 64)    2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_1_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_pw_1_relu (Activation)  (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pad_2 (ZeroPadding2D)   (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_dw_2 (DepthwiseConv2D)  (None, None, None, 64)    576       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_bn (BatchNormaliza (None, None, None, 64)    256       \n",
      "_________________________________________________________________\n",
      "conv_dw_2_relu (Activation)  (None, None, None, 64)    0         \n",
      "_________________________________________________________________\n",
      "conv_pw_2 (Conv2D)           (None, None, None, 128)   8192      \n",
      "_________________________________________________________________\n",
      "conv_pw_2_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_2_relu (Activation)  (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_3 (ZeroPadding2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_3 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_3_relu (Activation)  (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_3 (Conv2D)           (None, None, None, 128)   16384     \n",
      "_________________________________________________________________\n",
      "conv_pw_3_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_pw_3_relu (Activation)  (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_4 (ZeroPadding2D)   (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_4 (DepthwiseConv2D)  (None, None, None, 128)   1152      \n",
      "_________________________________________________________________\n",
      "conv_dw_4_bn (BatchNormaliza (None, None, None, 128)   512       \n",
      "_________________________________________________________________\n",
      "conv_dw_4_relu (Activation)  (None, None, None, 128)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_4 (Conv2D)           (None, None, None, 256)   32768     \n",
      "_________________________________________________________________\n",
      "conv_pw_4_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_4_relu (Activation)  (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_5 (ZeroPadding2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_5 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_5_relu (Activation)  (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_5 (Conv2D)           (None, None, None, 256)   65536     \n",
      "_________________________________________________________________\n",
      "conv_pw_5_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_pw_5_relu (Activation)  (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_6 (ZeroPadding2D)   (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_6 (DepthwiseConv2D)  (None, None, None, 256)   2304      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_bn (BatchNormaliza (None, None, None, 256)   1024      \n",
      "_________________________________________________________________\n",
      "conv_dw_6_relu (Activation)  (None, None, None, 256)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_6 (Conv2D)           (None, None, None, 512)   131072    \n",
      "_________________________________________________________________\n",
      "conv_pw_6_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_6_relu (Activation)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_7 (ZeroPadding2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_7 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_7_relu (Activation)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_7 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_7_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_7_relu (Activation)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_8 (ZeroPadding2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_8 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_8_relu (Activation)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_8 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_8_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_8_relu (Activation)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_9 (ZeroPadding2D)   (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_9 (DepthwiseConv2D)  (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_9_relu (Activation)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_9 (Conv2D)           (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_9_bn (BatchNormaliza (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_9_relu (Activation)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_10 (ZeroPadding2D)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_10 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_10_relu (Activation) (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_10 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_10_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_10_relu (Activation) (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_11 (ZeroPadding2D)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_11 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_11_relu (Activation) (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_11 (Conv2D)          (None, None, None, 512)   262144    \n",
      "_________________________________________________________________\n",
      "conv_pw_11_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_pw_11_relu (Activation) (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pad_12 (ZeroPadding2D)  (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_dw_12 (DepthwiseConv2D) (None, None, None, 512)   4608      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_bn (BatchNormaliz (None, None, None, 512)   2048      \n",
      "_________________________________________________________________\n",
      "conv_dw_12_relu (Activation) (None, None, None, 512)   0         \n",
      "_________________________________________________________________\n",
      "conv_pw_12 (Conv2D)          (None, None, None, 1024)  524288    \n",
      "_________________________________________________________________\n",
      "conv_pw_12_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_12_relu (Activation) (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_pad_13 (ZeroPadding2D)  (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_dw_13 (DepthwiseConv2D) (None, None, None, 1024)  9216      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_dw_13_relu (Activation) (None, None, None, 1024)  0         \n",
      "_________________________________________________________________\n",
      "conv_pw_13 (Conv2D)          (None, None, None, 1024)  1048576   \n",
      "_________________________________________________________________\n",
      "conv_pw_13_bn (BatchNormaliz (None, None, None, 1024)  4096      \n",
      "_________________________________________________________________\n",
      "conv_pw_13_relu (Activation) (None, None, None, 1024)  0         \n",
      "=================================================================\n",
      "Total params: 3,228,864\n",
      "Trainable params: 3,206,976\n",
      "Non-trainable params: 21,888\n",
      "_________________________________________________________________\n",
      "Found 1000 images belonging to 2 classes.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400 images belonging to 2 classes.\n",
      " train_labels shape (1000,)\n",
      " train_labels : \n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1]\n",
      " validation_labels shape (400,)\n",
      " validation_labels : \n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
      " 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1]\n",
      "Train on 1000 samples, validate on 400 samples\n",
      "Epoch 1/50\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 8.0492 - acc: 0.4960 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 2/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 3/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 4/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 5/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 6/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 7/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 8/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 9/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 10/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 11/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 12/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 13/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 14/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 15/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 16/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 17/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 18/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 19/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 20/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 21/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 22/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 23/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 24/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 25/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 26/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 27/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 28/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 29/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 30/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 31/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 32/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 33/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 34/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 35/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 36/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 37/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 38/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 39/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 40/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 41/50\n",
      "1000/1000 [==============================] - 16s 16ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 42/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 43/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 44/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 45/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 46/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 47/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 48/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 49/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "Epoch 50/50\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 8.0590 - acc: 0.5000 - val_loss: 8.0590 - val_acc: 0.5000\n",
      "-------------------------------------------------------------------\n",
      "------------------ Evalute the train set ------------------------\n",
      "-------------------------------------------------------------------\n",
      "Train loss: 8.059047746974617\n",
      "Train accuracy: 0.5\n",
      " y_pred_train shape (1000,)\n",
      " y_pred_train : \n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " y_pred_train again: \n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0]\n",
      "accuracy_score_train with normalize=True:  0.5\n",
      "accuracy_score_train with normalize=False :  500\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      0.50      0.67      1000\n",
      "    class 1       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.50      0.67      1000\n",
      "\n",
      "confusion_matrix : \n",
      " [[500 500]\n",
      " [  0   0]]\n",
      "Accuracy :  0.5\n",
      "Sensitivity :  1.0\n",
      "Specificity :  0.0\n",
      "-------------------------------------------------------------------\n",
      "------------------ Evalute the validation set ------------------------\n",
      "-------------------------------------------------------------------\n",
      "validation loss: 8.059047746974617\n",
      "validation accuracy: 0.5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/fatma-sayed/anaconda3/envs/keras-test/lib/python3.6/site-packages/sklearn/metrics/classification.py:1137: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples.\n",
      "  'recall', 'true', average, warn_for)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " y_pred_validation shape (400,)\n",
      " y_pred_validation : \n",
      "  [0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.\n",
      " 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0.]\n",
      " y_pred_validation again: \n",
      "  [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n",
      "accuracy_score_validation with normalize=True:  0.5\n",
      "accuracy_score_validation with normalize=False :  200\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "    class 0       1.00      0.50      0.67       400\n",
      "    class 1       0.00      0.00      0.00         0\n",
      "\n",
      "avg / total       1.00      0.50      0.67       400\n",
      "\n",
      "confusion_matrix : \n",
      " [[200 200]\n",
      " [  0   0]]\n",
      "Accuracy :  0.5\n",
      "Sensitivity :  1.0\n",
      "Specificity :  0.0\n",
      "-------------------------------------------------------------------\n",
      "------------------ Train Done -------------------------------------\n",
      "-------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf \n",
    "import keras\n",
    "import os\n",
    "\n",
    "from subprocess import check_output\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "from PIL import Image\n",
    "#from keras.applications.vgg16 import preprocess_input\n",
    "#from keras.applications.xception import preprocess_input\n",
    "#from keras.applications.inception_v3 import preprocess_input\n",
    "#from keras.applications.vgg19 import preprocess_input                \n",
    "#from keras.applications.resnet50 import preprocess_input            \n",
    "#from keras.applications.inception_resnet_v2 import preprocess_input               \n",
    "from keras.applications.mobilenet import preprocess_input               \n",
    "\n",
    "from keras.preprocessing import image\n",
    "\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "from sklearn.cross_validation import train_test_split\n",
    "\n",
    "from keras.utils import np_utils\n",
    "\n",
    "#from keras.applications.vgg16 import VGG16\n",
    "\n",
    "#from keras.applications.xception import Xception\n",
    "\n",
    "#from keras.applications.inception_v3 import InceptionV3\n",
    "\n",
    "#from keras.applications.vgg19 import VGG19\n",
    "\n",
    "#from keras.applications.resnet50 import ResNet50   \n",
    "\n",
    "#from keras.applications.inception_resnet_v2 import InceptionResNetV2    \n",
    "\n",
    "from keras.applications.mobilenet import MobileNet    \n",
    "\n",
    "from keras.models import Model, load_model\n",
    "\n",
    "from keras.layers import Dense, Dropout, Reshape\n",
    "\n",
    "from keras.optimizers import SGD\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Flatten \n",
    "from keras import backend as K\n",
    "from keras import applications\n",
    "\n",
    "\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0' #use GPU with ID=0\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.7 # maximun alloc gpu50% of MEM\n",
    "#config.gpu_options.allow_growth = True #allocate dynamically\n",
    "sess = tf.Session(config = config)\n",
    "keras.backend.set_session(sess)\n",
    "\n",
    "\n",
    "# dimensions of our images.\n",
    "img_width, img_height = 224, 224\n",
    "top_model_weights_path = 'bottleneck_fc_model_MobileNet_PP_data4.h5'  \n",
    "train_data_dir = '../data4_Train500_Test200/train'\n",
    "validation_data_dir = '../data4_Train500_Test200/validation'\n",
    "nb_train_samples = 1000\n",
    "nb_validation_samples = 400\n",
    "epochs = 50\n",
    "batch_size = 8  # batch size in flow_images_from_directory needs to correspond to the image number of the test images.\n",
    "\n",
    "\n",
    "def save_bottleneck_features():\n",
    "    datagen = ImageDataGenerator(rescale=1. / 255)\n",
    "\n",
    "    # build the Inception_ResNet_V2 network\n",
    "\n",
    "    model = applications.MobileNet(weights='imagenet', include_top=False)\n",
    "\n",
    "    model.summary()\n",
    "    \n",
    "    generator = datagen.flow_from_directory(\n",
    "        train_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    \n",
    "    bottleneck_features_train = model.predict_generator(\n",
    "        generator, nb_train_samples // batch_size)\n",
    "    np.save(open('DR1_bottleneck_features_train_MobileNet_PP_data4.npy', 'wb'),\n",
    "            bottleneck_features_train)\n",
    "\n",
    "    generator = datagen.flow_from_directory(\n",
    "        validation_data_dir,\n",
    "        target_size=(img_width, img_height),\n",
    "        batch_size=batch_size,\n",
    "        class_mode=None,\n",
    "        shuffle=False)\n",
    "    bottleneck_features_validation = model.predict_generator(\n",
    "        generator, nb_validation_samples // batch_size)\n",
    "    np.save(open('DR1_bottleneck_features_validation_MobileNet_PP_data4.npy', 'wb'),\n",
    "            bottleneck_features_validation)\n",
    "\n",
    "\n",
    "def train_top_model():\n",
    "    train_data = np.load(open('DR1_bottleneck_features_train_MobileNet_PP_data4.npy','rb'))\n",
    "    train_labels = np.array(\n",
    "        [0] * (nb_train_samples // 2) + [1] * (nb_train_samples // 2))\n",
    "\n",
    "    preprocess_input(train_data)   \n",
    "    \n",
    "    print(' train_labels shape',train_labels.shape)\n",
    "\n",
    "    print(' train_labels : \\n ',train_labels)\n",
    "\n",
    "    validation_data = np.load(open('DR1_bottleneck_features_validation_MobileNet_PP_data4.npy','rb'))\n",
    "    validation_labels = np.array(\n",
    "        [0] * (nb_validation_samples // 2) + [1] * (nb_validation_samples // 2))\n",
    "\n",
    "    preprocess_input(validation_data)   \n",
    "\n",
    "    print(' validation_labels shape',validation_labels.shape)\n",
    "\n",
    "    print(' validation_labels : \\n ',validation_labels)\n",
    "\n",
    "    model = Sequential()\n",
    "    model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "    model.add(Dense(256, activation='relu'))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(optimizer='rmsprop',\n",
    "                  loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "    model.fit(train_data, train_labels,\n",
    "              epochs=epochs,\n",
    "              batch_size=batch_size,\n",
    "              validation_data=(validation_data, validation_labels))\n",
    "    model.save_weights(top_model_weights_path)\n",
    "    \n",
    "    print('-------------------------------------------------------------------')\n",
    "    print('------------------ Evalute the train set ------------------------')\n",
    "    print('-------------------------------------------------------------------')\n",
    "\n",
    "    train_score = model.evaluate(train_data, train_labels, verbose=0) # nb_train_samples // batch_size, workers=1)\n",
    "    print('Train loss:', train_score[0])\n",
    "    print('Train accuracy:', train_score[1])\n",
    "\n",
    "    y_pred_train = np.squeeze(model.predict(train_data))\n",
    "    print(' y_pred_train shape',y_pred_train.shape)\n",
    "    print(' y_pred_train : \\n ',y_pred_train)\n",
    "\n",
    "    threshold = 0.5\n",
    "    y_pred_train = (y_pred_train > threshold)*1\n",
    "    #y_pred_train.astype(int)   \n",
    "    print(' y_pred_train again: \\n ',y_pred_train)\n",
    "    \n",
    "    accuracy_score_train = accuracy_score(train_labels, y_pred_train, normalize=True)\n",
    "    print('accuracy_score_train with normalize=True: ', accuracy_score_train)\n",
    "\n",
    "    accuracy_score_train = accuracy_score(train_labels, y_pred_train, normalize=False)\n",
    "    print('accuracy_score_train with normalize=False : ', accuracy_score_train)\n",
    "\n",
    "    target_names = ['class 0', 'class 1']\n",
    "\n",
    "    print(classification_report(y_pred_train, train_labels, target_names=target_names))\n",
    "\n",
    "    cm1 = confusion_matrix(y_pred_train, train_labels)\n",
    "    \n",
    "    print('confusion_matrix : \\n', cm1)\n",
    "\n",
    "    total1=sum(sum(cm1))\n",
    "\n",
    "    #####from confusion matrix calculate accuracy\n",
    "    accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
    "    print ('Accuracy : ', accuracy1)\n",
    "\n",
    "    sensitivity = cm1[0,0]/(cm1[0,0]+cm1[1,0])\n",
    "    print('Sensitivity : ', sensitivity )\n",
    "\n",
    "    Specificity = cm1[1,1]/(cm1[1,1]+cm1[0,1])\n",
    "    print('Specificity : ', Specificity )\n",
    "\n",
    "    print('-------------------------------------------------------------------')\n",
    "    print('------------------ Evalute the validation set ------------------------')\n",
    "    print('-------------------------------------------------------------------')\n",
    "\n",
    "    validation_score = model.evaluate(validation_data, validation_labels, verbose=0) # nb_train_samples // batch_size, workers=1)\n",
    "    print('validation loss:', validation_score[0])\n",
    "    print('validation accuracy:', validation_score[1])\n",
    "\n",
    "    y_pred_validation = np.squeeze(model.predict(validation_data))\n",
    "    print(' y_pred_validation shape',y_pred_validation.shape)\n",
    "    print(' y_pred_validation : \\n ',y_pred_validation)\n",
    "\n",
    "    y_pred_validation = (y_pred_validation > threshold)*1\n",
    "    #y_pred_train.astype(int)   \n",
    "    print(' y_pred_validation again: \\n ',y_pred_validation)\n",
    "    \n",
    "    accuracy_score_validation = accuracy_score(validation_labels, y_pred_validation, normalize=True)\n",
    "    print('accuracy_score_validation with normalize=True: ', accuracy_score_validation)\n",
    "\n",
    "    accuracy_score_validation = accuracy_score(validation_labels, y_pred_validation, normalize=False)\n",
    "    print('accuracy_score_validation with normalize=False : ', accuracy_score_validation)\n",
    "\n",
    "    print(classification_report(y_pred_validation, validation_labels, target_names=target_names))\n",
    "\n",
    "    cm1 = confusion_matrix(y_pred_validation, validation_labels)\n",
    "    \n",
    "    print('confusion_matrix : \\n', cm1)\n",
    "\n",
    "    total1=sum(sum(cm1))\n",
    "\n",
    "    #####from confusion matrix calculate accuracy\n",
    "    accuracy1=(cm1[0,0]+cm1[1,1])/total1\n",
    "    print ('Accuracy : ', accuracy1)\n",
    "\n",
    "    sensitivity = cm1[0,0]/(cm1[0,0]+cm1[1,0])\n",
    "    print('Sensitivity : ', sensitivity )\n",
    "\n",
    "    Specificity = cm1[1,1]/(cm1[1,1]+cm1[0,1])\n",
    "    print('Specificity : ', Specificity )\n",
    "\n",
    "\n",
    "save_bottleneck_features()\n",
    "train_top_model()\n",
    "\n",
    "print('-------------------------------------------------------------------')\n",
    "print('------------------ Train Done -------------------------------------')\n",
    "print('-------------------------------------------------------------------')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
